
version: 2

sources:
  - name: kafka
    schema: experiments
    tables:
      - name: data_stream
        description: "Example records stored in Kafka"
        # Uses https://github.com/dbt-labs/dbt-external-tables
        external:
          location: "kafka://{{ env_var('KAFKA_BROKER_PORT', 'default_port') }}"
          using: kafka
          options:
            kafka.bootstrap.servers: '{{ env_var("KAFKA_BOOTSTRAP_SERVERS", "localhost:9193") }}'
            subscribe: "data_stream"
            startingOffsets: earliest
models:
  - name: kafka_direct_model
    description: "Model to read directly from Kafka source table"
    config:
      materialized: incremental
      incremental_strategy: merge
      unique_key: id
      file_format: iceberg
    columns:
      - name: id
        description: "The primary key for this table"
        data_tests:
          - accepted_values:
              values: [1]
#  - name: my_first_dbt_model
#    description: "A starter dbt model"
#    columns:
#      - name: id
#        description: "The primary key for this table"
#        data_tests:
#          - unique
#          - not_null
#
#  - name: my_avro_out
#    custom_schema_name: default
#    description: "A starter dbt model"
#    columns:
#      - name: id
#        description: "The primary key for this table"
#        data_tests:
#          - unique
#          - not_null
